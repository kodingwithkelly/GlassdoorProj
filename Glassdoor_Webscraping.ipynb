{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Function to Scrape Glassdoor for Job Listings\n",
    "The code I used from @Kenarapfaik was created in 2020 and in 2021 Glassdoor has since changed its website. As such, I had to go through the process of debugging and find which xpaths were no longer relative; sadly, it was all of it. Moreover, in order to get salary from glassdoor, users must login to see the information. I thus found @williamxiell's function for logging in which I also adapted to fit this web scraping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Created on Thu Apr  2 09:32:36 2020\n",
    "author: Kenarapfaik (for scraping framework), williamxie11 (for login)\n",
    "url: https://github.com/arapfaik/scraping-glassdoor-selenium\n",
    "     https://github.com/williamxie11/glassdoor-interview-scraper/blob/master/scraper_v1.2.py\n",
    "\"\"\"\n",
    "\n",
    "''' \n",
    "Get jobs from glassdoor and put it into a dataframe\n",
    "'''\n",
    "def get_jobs(job, num_jobs, debug, path, sleep, username, password):    \n",
    "    #Initializing the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    #options.add_argument('headless')\n",
    "    \n",
    "    #Change the path to where chromedriver is in your home folder.\n",
    "    driver = webdriver.Chrome(executable_path=path, options=options)\n",
    "    driver.wait = WebDriverWait(driver, 10)\n",
    "    driver.set_window_size(1120, 1000)\n",
    "    \n",
    "    url = \"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=\" + job + \"&sc.keyword=\" + job + \"&locT=&locId=&jobType=\"\n",
    "    driver.get(url)\n",
    "    jobs = []\n",
    "    \n",
    "    # Test for the \"Sign Up\" prompt by clicking a job listing\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"MainCol\"]/div[1]/ul/li[1]/div[2]/a').click()\n",
    "    except ElementClickInterceptedException:\n",
    "        pass\n",
    "    \n",
    "    # Signing in \n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"JAModal\"]/div/div[2]/div[4]/div/div/a').click()\n",
    "        \n",
    "        user_field = driver.wait.until(EC.presence_of_element_located((By.ID, \"userEmail\")))\n",
    "        pw_field = driver.wait.until(EC.presence_of_element_located((By.ID, \"userPassword\")))\n",
    "        login_button = driver.find_element_by_xpath('//*[@id=\"LoginModal\"]/div/div/div[2]/div[2]/div[2]/div/div/div/div[3]/form/div[3]/div[1]/button')\n",
    "        \n",
    "        user_field.send_keys(username)\n",
    "        time.sleep(5)\n",
    "        user_field.send_keys(Keys.TAB)\n",
    "        time.sleep(1)\n",
    "        pw_field.send_keys(password)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        login_button.click()\n",
    "    except NoSuchElementException:\n",
    "        print('login failed')\n",
    "        pass\n",
    "\n",
    "    # If true, should be still looking for new jobs.\n",
    "    while len(jobs) < num_jobs:  \n",
    "        # Used to control the loop's rate i.e. to ensure that the server is not flooded with too many requests thereby blocking our ip.address\n",
    "        time.sleep(sleep)\n",
    "        \n",
    "        # Clicking through each job listing on the current page\n",
    "        job_buttons = driver.find_elements_by_xpath('//*[@data-test=\"job-link\"]') # Each job listing\n",
    "        \n",
    "        for job_button in job_buttons:\n",
    "            print(\"Progress: {}\".format(\"\" + str(len(jobs)) + \"/\" + str(num_jobs)))\n",
    "            if len(jobs) >= num_jobs:\n",
    "                break\n",
    "            # Click each job listing to access data\n",
    "            job_button.click()\n",
    "            time.sleep(1)\n",
    "            collected_successfully = False\n",
    "            \n",
    "            # Collecting company, location, job title, and description\n",
    "            while not collected_successfully:\n",
    "                try:                                                         \n",
    "                    company_name = driver.find_element_by_xpath('//*[@class=\"css-87uc0g e1tk4kwz1\"]').text\n",
    "                    location = driver.find_element_by_xpath('//*[@class=\"css-56kyx5 e1tk4kwz5\"]').text\n",
    "                    job_title = driver.find_element_by_xpath('//*[@class=\"css-1vg6q84 e1tk4kwz4\"]').text\n",
    "                    job_description = driver.find_element_by_xpath('//*[@class=\"jobDescriptionContent desc\"]').text\n",
    "                    collected_successfully = True\n",
    "                except:\n",
    "                    time.sleep(5)\n",
    "\n",
    "            # Collecting given salary estimate\n",
    "            try:\n",
    "                salary_estimate = driver.find_element_by_xpath('.//span[@class=\"css-56kyx5 css-16kxj2j e1wijj242\" and @data-test=\"detailSalary\"]').text\n",
    "            except NoSuchElementException:\n",
    "                salary_estimate = -1 #You need to set a \"not found value. It's important.\"\n",
    "\n",
    "            # Printing for debugging\n",
    "            if debug:\n",
    "                print(\"Job Title: {}\".format(job_title))\n",
    "                print(\"Salary Estimate: {}\".format(salary_estimate))\n",
    "                print(\"Job Description: {}\".format(job_description[:500]))\n",
    "                print(\"Company Name: {}\".format(company_name))\n",
    "                print(\"Location: {}\".format(location))\n",
    "            \n",
    "            # Collect size of company, industry, and sector\n",
    "            try:                                     \n",
    "                size = driver.find_element_by_xpath('//*[@id=\"JDCol\"]/div/article/div/div[1]/div/div/div[3]/div[2]/div[4]').text\n",
    "            except NoSuchElementException:\n",
    "                size = -1\n",
    "            try:\n",
    "                industry = driver.find_element_by_xpath('//*[@id=\"JDCol\"]/div/article/div/div[1]/div/div/div[3]/div[2]/div[3]').text\n",
    "            except NoSuchElementException:\n",
    "                industry = -1\n",
    "            try:\n",
    "                sector = driver.find_element_by_xpath('//*[@id=\"EmpBasicInfo\"]/div[1]/div/div[5]/span[2]').text\n",
    "            except NoSuchElementException:\n",
    "                sector = -1\n",
    "\n",
    "            if debug:\n",
    "                print(\"Size: {}\".format(size))\n",
    "                print(\"Industry: {}\".format(industry))\n",
    "                print(\"Sector: {}\".format(sector))\n",
    "                print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "\n",
    "            # Adding data to list to transform later into dataframe\n",
    "            jobs.append({\"Job Title\" : job_title,\n",
    "            \"Salary Estimate\" : salary_estimate,\n",
    "            \"Job Description\" : job_description,\n",
    "            \"Company Name\" : company_name,\n",
    "            \"Location\" : location,\n",
    "            \"Size\" : size,\n",
    "            \"Industry\" : industry,\n",
    "            \"Sector\" : sector})\n",
    "            \n",
    "            \n",
    "        # Clicking on the \"next page\" button\n",
    "        try:\n",
    "            driver.find_element_by_xpath('.//a[@data-test=\"pagination-next\"]').click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(jobs)  #This line converts the dictionary object into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/120\n",
      "Progress: 1/120\n",
      "Progress: 2/120\n",
      "Progress: 3/120\n",
      "Progress: 4/120\n",
      "Progress: 5/120\n",
      "Progress: 6/120\n",
      "Progress: 7/120\n",
      "Progress: 8/120\n",
      "Progress: 9/120\n",
      "Progress: 10/120\n",
      "Progress: 11/120\n",
      "Progress: 12/120\n",
      "Progress: 13/120\n",
      "Progress: 14/120\n",
      "Progress: 15/120\n",
      "Progress: 16/120\n",
      "Progress: 17/120\n",
      "Progress: 18/120\n",
      "Progress: 19/120\n",
      "Progress: 20/120\n",
      "Progress: 21/120\n",
      "Progress: 22/120\n",
      "Progress: 23/120\n",
      "Progress: 24/120\n",
      "Progress: 25/120\n",
      "Progress: 26/120\n",
      "Progress: 27/120\n",
      "Progress: 28/120\n",
      "Progress: 29/120\n",
      "Progress: 30/120\n",
      "Progress: 31/120\n",
      "Progress: 32/120\n",
      "Progress: 33/120\n",
      "Progress: 34/120\n",
      "Progress: 35/120\n",
      "Progress: 36/120\n",
      "Progress: 37/120\n",
      "Progress: 38/120\n",
      "Progress: 39/120\n",
      "Progress: 40/120\n",
      "Progress: 41/120\n",
      "Progress: 42/120\n",
      "Progress: 43/120\n",
      "Progress: 44/120\n",
      "Progress: 45/120\n",
      "Progress: 46/120\n",
      "Progress: 47/120\n",
      "Progress: 48/120\n",
      "Progress: 49/120\n",
      "Progress: 50/120\n",
      "Progress: 51/120\n",
      "Progress: 52/120\n",
      "Progress: 53/120\n",
      "Progress: 54/120\n",
      "Progress: 55/120\n",
      "Progress: 56/120\n",
      "Progress: 57/120\n",
      "Progress: 58/120\n",
      "Progress: 59/120\n",
      "Progress: 60/120\n",
      "Progress: 61/120\n",
      "Progress: 62/120\n",
      "Progress: 63/120\n",
      "Progress: 64/120\n",
      "Progress: 65/120\n",
      "Progress: 66/120\n",
      "Progress: 67/120\n",
      "Progress: 68/120\n",
      "Progress: 69/120\n",
      "Progress: 70/120\n",
      "Progress: 71/120\n",
      "Progress: 72/120\n",
      "Progress: 73/120\n",
      "Progress: 74/120\n",
      "Progress: 75/120\n",
      "Progress: 76/120\n",
      "Progress: 77/120\n",
      "Progress: 78/120\n",
      "Progress: 79/120\n",
      "Progress: 80/120\n",
      "Progress: 81/120\n",
      "Progress: 82/120\n",
      "Progress: 83/120\n",
      "Progress: 84/120\n",
      "Progress: 85/120\n",
      "Progress: 86/120\n",
      "Progress: 87/120\n",
      "Progress: 88/120\n",
      "Progress: 89/120\n",
      "Progress: 90/120\n",
      "Progress: 91/120\n",
      "Progress: 92/120\n",
      "Progress: 93/120\n",
      "Progress: 94/120\n",
      "Progress: 95/120\n",
      "Progress: 96/120\n",
      "Progress: 97/120\n",
      "Progress: 98/120\n",
      "Progress: 99/120\n",
      "Progress: 100/120\n",
      "Progress: 101/120\n",
      "Progress: 102/120\n",
      "Progress: 103/120\n",
      "Progress: 104/120\n",
      "Progress: 105/120\n",
      "Progress: 106/120\n",
      "Progress: 107/120\n",
      "Progress: 108/120\n",
      "Progress: 109/120\n",
      "Progress: 110/120\n",
      "Progress: 111/120\n",
      "Progress: 112/120\n",
      "Progress: 113/120\n",
      "Progress: 114/120\n",
      "Progress: 115/120\n",
      "Progress: 116/120\n",
      "Progress: 117/120\n",
      "Progress: 118/120\n",
      "Progress: 119/120\n",
      "Progress: 120/120\n"
     ]
    }
   ],
   "source": [
    "path = #your chrome driver path\n",
    "username = #your username\n",
    "password = #your password\n",
    "\n",
    "df = get_jobs('data analyst', 120, False, path, 15, username, password)\n",
    "df.to_csv('glassdoor_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Size</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Associate Research Analyst - Aviation Data Ana...</td>\n",
       "      <td>$55K - $112K (Glassdoor est.)</td>\n",
       "      <td>Friday, January 22, 2021\\n\\nCNA fosters an inc...</td>\n",
       "      <td>CNA Corporation\\n3.4</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Size: 501 to 1000 Employees</td>\n",
       "      <td>Industry: Aerospace &amp; Defense</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineer / Data Analyst – PBI, SQL, Kusto</td>\n",
       "      <td>$49K - $91K (Glassdoor est.)</td>\n",
       "      <td>Data Engineer / Data Analyst – PBI, SQL, Kusto...</td>\n",
       "      <td>Akvelon, Inc.\\n4.1</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>Size: 501 to 1000 Employees</td>\n",
       "      <td>Industry: Information Technology</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$50K - $90K (Glassdoor est.)</td>\n",
       "      <td>Who We Are\\n\\n\\nThe School Systems and Data An...</td>\n",
       "      <td>New Visions Central Office\\n4.0</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Size: 501 to 1000 Employees</td>\n",
       "      <td>Industry: Education</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>-1</td>\n",
       "      <td>We are seeking a resource who loves data, anal...</td>\n",
       "      <td>TalentDash</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Size: 1 to 50 Employees</td>\n",
       "      <td>Industry: Information Technology</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$40K - $74K (Glassdoor est.)</td>\n",
       "      <td>Essen is currently seeking a Full-time Data An...</td>\n",
       "      <td>Essen Health Care\\n3.0</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Size: 1001 to 5000 Employees</td>\n",
       "      <td>Industry: Health Care</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$35K - $64K (Glassdoor est.)</td>\n",
       "      <td>Do you want to be part of a team that encourag...</td>\n",
       "      <td>MassMutual\\n3.8</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Size: 5001 to 10000 Employees</td>\n",
       "      <td>Industry: Insurance</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$35K - $64K (Glassdoor est.)</td>\n",
       "      <td>Do you want to be part of a team that encourag...</td>\n",
       "      <td>MassMutual\\n3.8</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Size: 5001 to 10000 Employees</td>\n",
       "      <td>Industry: Insurance</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$35K - $64K (Glassdoor est.)</td>\n",
       "      <td>Data Analyst Job Description\\nDaisyBill is see...</td>\n",
       "      <td>DaisyBill</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Size: N/A</td>\n",
       "      <td>Industry: N/A</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Analyst, Data Science - Product Analytics</td>\n",
       "      <td>$35K - $64K (Glassdoor est.)</td>\n",
       "      <td>This is a great opportunity to join Vrbos glob...</td>\n",
       "      <td>Expedia Group\\n4.0</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Size: 10000+ Employees</td>\n",
       "      <td>Industry: Information Technology</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>$35K - $64K (Glassdoor est.)</td>\n",
       "      <td>Overview:\\nGuidehouse is a leading management ...</td>\n",
       "      <td>Guidehouse\\n3.7</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Size: 5001 to 10000 Employees</td>\n",
       "      <td>Industry: Business Services</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job Title  \\\n",
       "0    Associate Research Analyst - Aviation Data Ana...   \n",
       "1       Data Engineer / Data Analyst – PBI, SQL, Kusto   \n",
       "2                                         Data Analyst   \n",
       "3                                         Data Analyst   \n",
       "4                                         Data Analyst   \n",
       "..                                                 ...   \n",
       "115                                       Data Analyst   \n",
       "116                                       Data Analyst   \n",
       "117                                       Data Analyst   \n",
       "118          Analyst, Data Science - Product Analytics   \n",
       "119                                       Data Analyst   \n",
       "\n",
       "                   Salary Estimate  \\\n",
       "0    $55K - $112K (Glassdoor est.)   \n",
       "1     $49K - $91K (Glassdoor est.)   \n",
       "2     $50K - $90K (Glassdoor est.)   \n",
       "3                               -1   \n",
       "4     $40K - $74K (Glassdoor est.)   \n",
       "..                             ...   \n",
       "115   $35K - $64K (Glassdoor est.)   \n",
       "116   $35K - $64K (Glassdoor est.)   \n",
       "117   $35K - $64K (Glassdoor est.)   \n",
       "118   $35K - $64K (Glassdoor est.)   \n",
       "119   $35K - $64K (Glassdoor est.)   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Friday, January 22, 2021\\n\\nCNA fosters an inc...   \n",
       "1    Data Engineer / Data Analyst – PBI, SQL, Kusto...   \n",
       "2    Who We Are\\n\\n\\nThe School Systems and Data An...   \n",
       "3    We are seeking a resource who loves data, anal...   \n",
       "4    Essen is currently seeking a Full-time Data An...   \n",
       "..                                                 ...   \n",
       "115  Do you want to be part of a team that encourag...   \n",
       "116  Do you want to be part of a team that encourag...   \n",
       "117  Data Analyst Job Description\\nDaisyBill is see...   \n",
       "118  This is a great opportunity to join Vrbos glob...   \n",
       "119  Overview:\\nGuidehouse is a leading management ...   \n",
       "\n",
       "                        Company Name        Location  \\\n",
       "0               CNA Corporation\\n3.4   Arlington, VA   \n",
       "1                 Akvelon, Inc.\\n4.1    Bellevue, WA   \n",
       "2    New Visions Central Office\\n4.0    New York, NY   \n",
       "3                         TalentDash     Chicago, IL   \n",
       "4             Essen Health Care\\n3.0    New York, NY   \n",
       "..                               ...             ...   \n",
       "115                  MassMutual\\n3.8      Boston, MA   \n",
       "116                  MassMutual\\n3.8      Boston, MA   \n",
       "117                        DaisyBill    New York, NY   \n",
       "118               Expedia Group\\n4.0      Austin, TX   \n",
       "119                  Guidehouse\\n3.7  Washington, DC   \n",
       "\n",
       "                              Size                          Industry  Sector  \n",
       "0      Size: 501 to 1000 Employees     Industry: Aerospace & Defense      -1  \n",
       "1      Size: 501 to 1000 Employees  Industry: Information Technology      -1  \n",
       "2      Size: 501 to 1000 Employees               Industry: Education      -1  \n",
       "3          Size: 1 to 50 Employees  Industry: Information Technology      -1  \n",
       "4     Size: 1001 to 5000 Employees             Industry: Health Care      -1  \n",
       "..                             ...                               ...     ...  \n",
       "115  Size: 5001 to 10000 Employees               Industry: Insurance      -1  \n",
       "116  Size: 5001 to 10000 Employees               Industry: Insurance      -1  \n",
       "117                      Size: N/A                     Industry: N/A      -1  \n",
       "118         Size: 10000+ Employees  Industry: Information Technology      -1  \n",
       "119  Size: 5001 to 10000 Employees       Industry: Business Services      -1  \n",
       "\n",
       "[120 rows x 8 columns]"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Web Scraping Issue\n",
    "I ran into a personal problem that the script would not scrape the full 1000 listings because of my internet speed and would fail around 160 listings. Therefore, I decided to scrape the listings by increments of 120 (this is because 30 listings are on each page so I scrape 4 pages at a time). In the end I had 7 separate csv files which I merged into a consolidated csv file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
